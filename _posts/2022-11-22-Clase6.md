---
layout: post
title: User centric y FAccT
---

## FAccT

A medida que avanza la tecnología existe gran interés de las empresas e instituciones de tomar decisiones basadas en datos, para eso se han desarrollado una amplia gama de algoritmos capaces de ayudar a esta toma de decisiones. Sin embargo, estos algoritmos contienen diversos riesgos en su codificación y tener sesgo implícitos que pueden afectar en decisiones discriminatorias para los individuos

Los sistemas recomendadores no están exentos de estos riesgos, por esa razón es de gran importancia considerar los siguientes aspectos a la hora de construir o desarrollar un sistema de recomendación.

- Fairness (Equidad)
- Accountability (Explicabilidad)
- Transparency (Transparencia)

En este sentido la **equidad** se refiere a la propiedad de ser justo o equitativo, es decir la tarea de considerar los impactos dispares de las recomendaciones en algunas clases de usuarios. Por ejemplo, un sistema de recomendación que sugiera vacantes de empleo debe garantizar que los usuarios masculinos y femeninos con calificaciones comparables reciban sugerencias de trabajo con rango e ingresos comparables.

La **explicabilidad** significa permitir que las personas afectadas por el resultado de un sistema de IA entiendan cómo se llegó a él. Es decir, debe proporcionar información fácil de entender, que les permita cuestionar el resultado, los factores y la lógica que condujeron a un resultado.

Cuando hablamos de **transparencia** en este contexto nos referimos a la capacidad de saber qué datos se utilizan, cómo se utilizan, quiénes los utilizan, para qué los utilizan y cómo se llega a partir de los datos a tomar las decisiones, o muchas veces cómo estos algoritmos pueden influenciar las decisiones de un gran número de personas. La transparencia va más allá de un tema tecnológico, y cada vez se hace más compleja en la medida que los algoritmos de machine learning y deep learning se vuelven más sofisticados, con mayor cantidad de parámetros, aumentando la dificultad de interpretarlos. Muchas veces hablamos de algoritmos tipo "caja negra", ya que es difícil conocer lo que ocurre internamente para llegar al resultado.


Un ejemplo complejo a analizar, es el sistema de recomendaciones de YouTube se basa en el principio de ayudar a las personas a encontrar los vídeos que quieren ver, pero que todavía no han descubierto. De esta esta forma, YouTube muestra vídeos recomendados en su página de inicio, pero también en el panel lateral. Debido al gran volumen de videos y audiencias que maneja Youtube, sería una terea muy difícil navegar por todos ellos. El tener un buen sistema de recomendación genera una cantidad significativa de audiencia en YouTube.

El antiguo sistema de recomendación de Youtube, sólo clasificaba los videos según su popularidad para crear una gran página de "Tendencias". No mucha gente vio esos videos y la mayoría de la audiencia de YouTube provenía de búsquedas o enlaces compartidos fuera de la plataforma. Por otra parte, este algoritmo no evitaba que un usuario viera videos conspirativos o de fakes news, tampoco consideraba los likes de los usuarios para generar el perfil de usuario para recomendar.

Ahora tienen un sistema de multitask learning con el fin de aprender varias cosas a la vez, clasificando miles de millones de videos para recomendar contenido adaptado a los intereses específicos de los usuarios, considerando la cantidad de clics en los videos, el tiempo de visualización, la respuesta a las encuestas, los compartidos, los likes y dislikes que proporcionan los usuarios, y la información personal que proporcionan los usuarios. A pesar de la explicabilidad, la complejidad y volumen de información dificulta la transparencia de los algoritmos.

También declaran que, en 2017 incorporan evaluación del aprendizaje automático para asegurarse de que el sistema de recomendación fuera justo para las comunidades marginadas, impulsando el sistema para la equidad a lo largo de todos los grupos protegidos, como la comunidad LGBTQ+

Sin embargo, sigue siendo una tarea muy compleja incorporar en el video la calidad del contenido que se está exponiendo o si contiene noticias falsas. Lo que sigue siendo alguien preocupante por el nivel de exposición que tienen los videos de Youtube y porque la gran mayoría de las personas (sobre un 75%), independiente de su edad, sigue las recomendaciones de Youtube.


### Referencias
https://blog.youtube/intl/es-419/inside-youtube/sobre-el-sistema-de-recomendaciones-de-youtube/

